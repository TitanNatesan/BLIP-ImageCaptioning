{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor and model from the local directory\n",
    "processor = BlipProcessor.from_pretrained(\"./blip_image_captioning\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"./blip_image_captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a local image\n",
    "local_image_path = r\"test\\img1.webp\"  # Replace with your local image path\n",
    "raw_image = Image.open(local_image_path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional image captioning with controlled length\n",
    "text = \"wallpaper of\"\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(\n",
    "    **inputs,\n",
    "    max_length=30,  # Maximum length of the generated caption\n",
    "    min_length=5,   # Minimum length of the generated caption\n",
    "    length_penalty=2.0,  # Length penalty to encourage longer sentences\n",
    "    num_beams=4  # Number of beams for beam search (for better quality)\n",
    ")\n",
    "print(\"Conditional Caption:\", processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional image captioning with controlled length\n",
    "inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(\n",
    "    **inputs,\n",
    "    max_length=30,  # Maximum length of the generated caption\n",
    "    min_length=5,   # Minimum length of the generated caption\n",
    "    length_penalty=2.0,  # Length penalty to encourage longer sentences\n",
    "    num_beams=4  # Number of beams for beam search (for better quality)\n",
    ")\n",
    "print(\"Unconditional Caption:\", processor.decode(out[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
